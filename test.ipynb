{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "sys.path.insert(0,'../')\n",
    "from SRL_consistency_evaluator import dataio\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "import glob\n",
    "import os\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from transformers import *\n",
    "from tqdm import tqdm, trange\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from seqeval.metrics import f1_score\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model', required=False, help='모델 폴더', default='./model/')\n",
    "parser.add_argument('--result', required=False, help='결과 저장 파일', default='./result.txt')\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 256\n",
    "batch_size = 6\n",
    "\n",
    "try:\n",
    "    dir_path = os.path.dirname(os.path.abspath( __file__ ))\n",
    "except:\n",
    "    dir_path = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fname):\n",
    "    with open(fname, 'r') as f:\n",
    "        d = f.readlines()\n",
    "        \n",
    "    ori_data = dataio.conll2tagseq(d)\n",
    "    tgt_data = dataio.data2tgt_data(ori_data)\n",
    "    \n",
    "    return tgt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class for_BERT():\n",
    "    \n",
    "    def __init__(self, mode='training'):\n",
    "        self.mode = mode\n",
    "        \n",
    "        with open(dir_path+'/data/tag2idx.json','r') as f:\n",
    "            self.tag2idx = json.load(f)\n",
    "            \n",
    "        self.idx2tag = dict(zip(self.tag2idx.values(),self.tag2idx.keys()))\n",
    "        \n",
    "        # load pretrained BERT tokenizer\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
    "        \n",
    "        # load BERT tokenizer with untokenizing frames\n",
    "        never_split_tuple = (\"[UNK]\", \"[SEP]\", \"[PAD]\", \"[CLS]\", \"[MASK]\")\n",
    "        added_never_split = []\n",
    "        added_never_split.append('<tgt>')\n",
    "        added_never_split.append('</tgt>')\n",
    "        added_never_split_tuple = tuple(added_never_split)\n",
    "        never_split_tuple += added_never_split_tuple\n",
    "        vocab_file_path = dir_path+'/data/bert-multilingual-cased-dict-add-frames'\n",
    "        self.tokenizer_with_frame = BertTokenizer(vocab_file_path, do_lower_case=False, max_len=256, never_split=never_split_tuple)\n",
    "        \n",
    "    def idx2tag(self, predictions):\n",
    "        pred_tags = [self.idx2tag[p_i] for p in predictions for p_i in p]\n",
    "        \n",
    "        # bert tokenizer and assign to the first token\n",
    "    def bert_tokenizer(self, text):\n",
    "        orig_tokens = text.split(' ')\n",
    "        bert_tokens = []\n",
    "        orig_to_tok_map = []\n",
    "        bert_tokens.append(\"[CLS]\")\n",
    "        for orig_token in orig_tokens:\n",
    "            orig_to_tok_map.append(len(bert_tokens))\n",
    "            bert_tokens.extend(self.tokenizer_with_frame.tokenize(orig_token))\n",
    "        bert_tokens.append(\"[SEP]\")\n",
    "\n",
    "        return orig_tokens, bert_tokens, orig_to_tok_map\n",
    "    \n",
    "    def convert_to_bert_input(self, input_data):\n",
    "        tokenized_texts, args = [],[]\n",
    "        orig_tok_to_maps = []\n",
    "        for i in range(len(input_data)):    \n",
    "            data = input_data[i]\n",
    "            text = ' '.join(data[0])\n",
    "            orig_tokens, bert_tokens, orig_to_tok_map = self.bert_tokenizer(text)\n",
    "            orig_tok_to_maps.append(orig_to_tok_map)\n",
    "            tokenized_texts.append(bert_tokens)\n",
    "\n",
    "            if self.mode == 'training':\n",
    "                ori_args = data[2]\n",
    "                arg_sequence = []\n",
    "                for i in range(len(bert_tokens)):\n",
    "                    if i in orig_to_tok_map:\n",
    "                        idx = orig_to_tok_map.index(i)\n",
    "                        ar = ori_args[idx]\n",
    "                        arg_sequence.append(ar)\n",
    "                    else:\n",
    "                        arg_sequence.append('X')\n",
    "                args.append(arg_sequence)\n",
    "\n",
    "        input_ids = pad_sequences([self.tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
    "                              maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "        orig_tok_to_maps = pad_sequences(orig_tok_to_maps, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\", value=-1)\n",
    "        \n",
    "        if self.mode =='training':\n",
    "            arg_ids = pad_sequences([[self.tag2idx.get(ar) for ar in arg] for arg in args],\n",
    "                                    maxlen=MAX_LEN, value=self.tag2idx[\"X\"], padding=\"post\",\n",
    "                                    dtype=\"long\", truncating=\"post\")\n",
    "\n",
    "        attention_masks = [[float(i>0) for i in ii] for ii in input_ids]    \n",
    "        data_inputs = torch.tensor(input_ids)\n",
    "        data_orig_tok_to_maps = torch.tensor(orig_tok_to_maps)\n",
    "        data_masks = torch.tensor(attention_masks)\n",
    "        \n",
    "        if self.mode == 'training':\n",
    "            data_args = torch.tensor(arg_ids)\n",
    "            bert_inputs = TensorDataset(data_inputs, data_orig_tok_to_maps, data_args, data_masks)\n",
    "        else:\n",
    "            bert_inputs = TensorDataset(data_inputs, data_orig_tok_to_maps, data_masks)\n",
    "        return bert_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_io = for_BERT(mode='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=2).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "def test(model_fname, tst):\n",
    "    model_path = '/disk/data/models/kosrl_1105/'\n",
    "    models = glob.glob(model_path+'*.pt')\n",
    "    \n",
    "    result_path = model_path = '/disk/data/models/result_kosrl_1105/'\n",
    "    results = []\n",
    "    \n",
    "\n",
    "    model = torch.load(model_fname)\n",
    "    model.eval()\n",
    "\n",
    "    tst_data = bert_io.convert_to_bert_input(tst)\n",
    "    sampler = RandomSampler(tst_data)\n",
    "    tst_dataloader = DataLoader(tst_data, sampler=sampler, batch_size=batch_size)\n",
    "\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    pred_args, true_args = [],[]\n",
    "    for batch in tst_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_orig_tok_to_maps, b_input_args, b_input_masks = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            tmp_eval_loss = model(b_input_ids, token_type_ids=None,\n",
    "                          attention_mask=b_input_masks, labels=b_input_args)\n",
    "            logits = model(b_input_ids, token_type_ids=None,\n",
    "                           attention_mask=b_input_masks)\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "\n",
    "        b_pred_args = [list(p) for p in np.argmax(logits, axis=2)]\n",
    "        b_true_args = b_input_args.to('cpu').numpy().tolist()\n",
    "\n",
    "\n",
    "        eval_loss += tmp_eval_loss.mean().item()\n",
    "\n",
    "        nb_eval_examples += b_input_ids.size(0)\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "        for b_idx in range(len(b_true_args)):\n",
    "\n",
    "            input_id = b_input_ids[b_idx]\n",
    "            orig_tok_to_map = b_input_orig_tok_to_maps[b_idx]                \n",
    "            pred_arg_bert = b_pred_args[b_idx]\n",
    "            true_arg_bert = b_true_args[b_idx]\n",
    "\n",
    "            pred_arg, true_arg = [],[]\n",
    "            \n",
    "            try:\n",
    "                for tok_idx in orig_tok_to_map:\n",
    "                    if tok_idx != -1:\n",
    "                        tok_id = int(input_id[tok_idx])\n",
    "                        if tok_id == 1:\n",
    "                            pass\n",
    "                        elif tok_id == 2:\n",
    "                            pass\n",
    "                        else:\n",
    "                            pred_arg.append(pred_arg_bert[tok_idx])\n",
    "                            true_arg.append(true_arg_bert[tok_idx])\n",
    "\n",
    "                pred_args.append(pred_arg)\n",
    "                true_args.append(true_arg)\n",
    "            except KeyboardInterrupt:\n",
    "                raise\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "#         break\n",
    "\n",
    "\n",
    "    pred_arg_tags_old = [[bert_io.idx2tag[p_i] for p_i in p] for p in pred_args]\n",
    "\n",
    "    pred_arg_tags = []\n",
    "    for old in pred_arg_tags_old:\n",
    "        new = []\n",
    "        for t in old:\n",
    "            if t == 'X':\n",
    "                new_t = 'O'\n",
    "            else:\n",
    "                new_t = t\n",
    "            new.append(new_t)\n",
    "        pred_arg_tags.append(new)\n",
    "\n",
    "    valid_arg_tags = [[bert_io.idx2tag[v_i] for v_i in v] for v in true_args]\n",
    "    f1 = f1_score(pred_arg_tags, valid_arg_tags)\n",
    "\n",
    "    print(\"Validation loss: {}\".format(eval_loss/nb_eval_steps))\n",
    "    print(\"Validation F1-Score: {}\".format(f1_score(pred_arg_tags, valid_arg_tags)))\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/disk/project/corpus/test_1.conll\n",
      "Validation loss: 0.15163536369800568\n",
      "Validation F1-Score: 0.6428571428571429\n",
      "1:0.6428571428571429\n",
      "/disk/project/corpus/test_2.conll\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7a9380f5a16f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtst_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-8a335f06c8e8>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model_fname, tst)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtst_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_bert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtst_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtst_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtst_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-cf2ac9dd7925>\u001b[0m in \u001b[0;36mconvert_to_bert_input\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m     69\u001b[0m                                     dtype=\"long\", truncating=\"post\")\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mattention_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0mdata_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mdata_orig_tok_to_maps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_tok_to_maps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-cf2ac9dd7925>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     69\u001b[0m                                     dtype=\"long\", truncating=\"post\")\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mattention_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0mdata_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mdata_orig_tok_to_maps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_tok_to_maps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-cf2ac9dd7925>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     69\u001b[0m                                     dtype=\"long\", truncating=\"post\")\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mattention_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0mdata_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mdata_orig_tok_to_maps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_tok_to_maps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ns = [1,2,3,4,5,6,7,8,9,10]\n",
    "ns = [6,7,8,9,10]\n",
    "model_fname = '/disk/data/models/korval/ko-srl-epoch-4.pt'\n",
    "result = []\n",
    "for n in ns:\n",
    "    tst_fname = '/disk/project/corpus/test_'+str(n)+'.conll'\n",
    "    print(tst_fname)\n",
    "    tst = load_data(tst_fname)\n",
    "    \n",
    "    f1 = test(model_fname, tst)\n",
    "    \n",
    "    line = str(n)+':'+str(f1)\n",
    "    print(line)\n",
    "    result.append(line)\n",
    "\n",
    "with open('/disk/project/corpus/eval_result.txt','w') as f:\n",
    "    for i in result:\n",
    "        f.write(i+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
