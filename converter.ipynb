{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "from pprint import pprint\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[[[1], [1]], [[0], [0]]]\n"
     ]
    }
   ],
   "source": [
    "s = 100\n",
    "\n",
    "l = [[[0],[0]],[[1],[1]],[[2],[2]],[[3],[3]]]\n",
    "\n",
    "a = len(l)\n",
    "\n",
    "z = int(a * (50/100))\n",
    "print(z)\n",
    "\n",
    "r = random.sample(l, k=z)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trn data\n",
    "val_dir = '/disk/project/koreanvalidation/input/val/'\n",
    "val_files = glob.glob(val_dir+'*')\n",
    "\n",
    "# trn_save dir\n",
    "trn_save_fname = '/disk/project/corpus/val.conll'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/disk/project/koreanvalidation/input/val/NWRW1800000032-0017.json', '/disk/project/koreanvalidation/input/val/NWRW1800000029-0156.json', '/disk/project/koreanvalidation/input/val/NWRW1800000021-0026.json', '/disk/project/koreanvalidation/input/val/NWRW1800000041-0329.json', '/disk/project/koreanvalidation/input/val/NWRW1800000026-0039.json', '/disk/project/koreanvalidation/input/val/NWRW1800000052-0284.json', '/disk/project/koreanvalidation/input/val/NWRW1800000033-0369.json', '/disk/project/koreanvalidation/input/val/NWRW1800000022-0081.json', '/disk/project/koreanvalidation/input/val/NWRW1800000044-0172.json', '/disk/project/koreanvalidation/input/val/NWRW1800000037-0146.json', '/disk/project/koreanvalidation/input/val/NWRW1800000044-0246.json', '/disk/project/koreanvalidation/input/val/NWRW1800000041-0332.json', '/disk/project/koreanvalidation/input/val/NWRW1800000041-0055.json', '/disk/project/koreanvalidation/input/val/NWRW1800000042-0142.json', '/disk/project/koreanvalidation/input/val/NWRW1800000045-0028.json', '/disk/project/koreanvalidation/input/val/NWRW1800000033-0350.json', '/disk/project/koreanvalidation/input/val/NWRW1800000044-0322.json', '/disk/project/koreanvalidation/input/val/NWRW1800000037-0154.json', '/disk/project/koreanvalidation/input/val/NWRW1800000044-0094.json', '/disk/project/koreanvalidation/input/val/NWRW1800000041-0354.json', '/disk/project/koreanvalidation/input/val/NWRW1800000054-0049.json', '/disk/project/koreanvalidation/input/val/NWRW1800000048-0047.json', '/disk/project/koreanvalidation/input/val/NWRW1800000022-0097.json', '/disk/project/koreanvalidation/input/val/NWRW1800000021-0345.json', '/disk/project/koreanvalidation/input/val/NWRW1800000026-0295.json', '/disk/project/koreanvalidation/input/val/NWRW1800000046-0217.json', '/disk/project/koreanvalidation/input/val/NWRW1800000021-0336.json', '/disk/project/koreanvalidation/input/val/NWRW1800000048-0116.json', '/disk/project/koreanvalidation/input/val/NWRW1800000021-0024.json', '/disk/project/koreanvalidation/input/val/NWRW1800000022-0430.json', '/disk/project/koreanvalidation/input/val/NWRW1800000030-0068.json', '/disk/project/koreanvalidation/input/val/NWRW1800000041-0155.json', '/disk/project/koreanvalidation/input/val/NWRW1800000025-0095.json', '/disk/project/koreanvalidation/input/val/NWRW1800000044-0125.json', '/disk/project/koreanvalidation/input/val/NWRW1800000056-0220.json', '/disk/project/koreanvalidation/input/val/NWRW1800000046-0178.json', '/disk/project/koreanvalidation/input/val/NWRW1800000045-0338.json', '/disk/project/koreanvalidation/input/val/NWRW1800000024-0270.json', '/disk/project/koreanvalidation/input/val/NWRW1800000021-0156.json', '/disk/project/koreanvalidation/input/val/NWRW1800000024-0468.json', '/disk/project/koreanvalidation/input/val/NWRW1800000045-0391.json', '/disk/project/koreanvalidation/input/val/NWRW1800000022-0299.json', '/disk/project/koreanvalidation/input/val/NWRW1800000041-0350.json', '/disk/project/koreanvalidation/input/val/NWRW1800000021-0207.json', '/disk/project/koreanvalidation/input/val/NWRW1800000042-0022.json', '/disk/project/koreanvalidation/input/val/NWRW1800000054-0068.json', '/disk/project/koreanvalidation/input/val/NWRW1800000028-0028.json', '/disk/project/koreanvalidation/input/val/NWRW1800000056-0025.json', '/disk/project/koreanvalidation/input/val/NWRW1800000041-0061.json', '/disk/project/koreanvalidation/input/val/NWRW1800000024-0321.json', '/disk/project/koreanvalidation/input/val/NWRW1800000022-0361.json', '/disk/project/koreanvalidation/input/val/NWRW1800000044-0236.json', '/disk/project/koreanvalidation/input/val/NWRW1800000025-0368.json', '/disk/project/koreanvalidation/input/val/NWRW1800000026-0183.json', '/disk/project/koreanvalidation/input/val/NWRW1800000024-0472.json', '/disk/project/koreanvalidation/input/val/NWRW1800000041-0016.json', '/disk/project/koreanvalidation/input/val/NWRW1800000022-0269.json', '/disk/project/koreanvalidation/input/val/NWRW1800000048-0001.json', '/disk/project/koreanvalidation/input/val/NWRW1800000026-0348.json', '/disk/project/koreanvalidation/input/val/NWRW1800000038-0150.json', '/disk/project/koreanvalidation/input/val/NWRW1800000022-0417.json', '/disk/project/koreanvalidation/input/val/NWRW1800000048-0025.json', '/disk/project/koreanvalidation/input/val/NWRW1800000041-0005.json', '/disk/project/koreanvalidation/input/val/NWRW1800000048-0142.json', '/disk/project/koreanvalidation/input/val/NWRW1800000037-0370.json', '/disk/project/koreanvalidation/input/val/NWRW1800000030-0156.json', '/disk/project/koreanvalidation/input/val/NWRW1800000026-0219.json', '/disk/project/koreanvalidation/input/val/NWRW1800000024-0379.json', '/disk/project/koreanvalidation/input/val/NWRW1800000044-0006.json', '/disk/project/koreanvalidation/input/val/NWRW1800000048-0011.json', '/disk/project/koreanvalidation/input/val/NWRW1800000022-0337.json', '/disk/project/koreanvalidation/input/val/NWRW1800000024-0450.json', '/disk/project/koreanvalidation/input/val/NWRW1800000041-0145.json']\n"
     ]
    }
   ],
   "source": [
    "print(val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_id(item, word):\n",
    "    word_id = False\n",
    "    e = item['end']\n",
    "    for i in range(len(word)):\n",
    "        w = word[i]\n",
    "        if w['begin'] <= e <= w['end']:\n",
    "            word_id = i\n",
    "            break\n",
    "\n",
    "    return word_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words2tokens(words):\n",
    "    tokens = []\n",
    "    for i in words:\n",
    "        tokens.append(i['form'])\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_for_sent(srls, words):\n",
    "    result = []\n",
    "    tokens = words2tokens(words)\n",
    "    for srl in srls:\n",
    "        if srl:\n",
    "            pred_id = get_word_id(srl['predicate'], words)\n",
    "            pred = srl['predicate']['lemma'] + '.' + str(srl['predicate']['sense_id'])            \n",
    "            \n",
    "            preds = ['_' for i in range(len(tokens))]\n",
    "            senses = ['_' for i in range(len(tokens))]\n",
    "            preds[pred_id] = 'PRED'\n",
    "            senses[pred_id] = pred\n",
    "            \n",
    "            args = ['O' for i in range(len(tokens))]\n",
    "            \n",
    "            for arg in srl['argument']:\n",
    "                arg_id = get_word_id(arg, words)\n",
    "                label = arg['label'].replace('-', '_')\n",
    "                args[arg_id] = label\n",
    "                \n",
    "            sent = []\n",
    "            sent.append(tokens)\n",
    "            sent.append(preds)\n",
    "            sent.append(senses)\n",
    "            sent.append(args)\n",
    "            \n",
    "            result.append(sent)\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converter(files, save_fname):\n",
    "    conll = []\n",
    "    \n",
    "    doc_list = []\n",
    "    for fname in files:        \n",
    "        docid = fname.split('/')[-1].split('.')[0]\n",
    "        doc_list.append(docid)\n",
    "        \n",
    "        with open(fname, 'r') as f:\n",
    "            d = json.load(f)\n",
    "            \n",
    "        for doc in d['document']:\n",
    "            for sent in doc['sentence']:\n",
    "                words = sent['word']\n",
    "                srl = sent['SRL']\n",
    "                srl_conll = convert_for_sent(srl, words)\n",
    "                \n",
    "                conll += srl_conll\n",
    "                \n",
    "    doc_ids = ','.join(doc_list)                \n",
    "    with open(save_fname, 'w') as f:\n",
    "        f.write('#doc_ids: '+doc_ids+'\\n')\n",
    "        for sent in conll:\n",
    "            tokens, preds, senses, args = sent[0], sent[1], sent[2], sent[3]            \n",
    "            n = 0\n",
    "            for i in range(len(tokens)):\n",
    "                line = str(n) + '\\t' + tokens[i] + '\\t' + preds[i] + '\\t' + senses[i] + '\\t' + args[i] + '\\n'\n",
    "                n +=1\n",
    "                f.write(line)\n",
    "            f.write('\\n')\n",
    "        \n",
    "    print('saved to:', save_fname)\n",
    "    print('saved srls:', len(conll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /disk/project/corpus/val.conll\n",
      "saved srls: 4488\n"
     ]
    }
   ],
   "source": [
    "# convert train data\n",
    "converter(val_files, trn_save_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720\n"
     ]
    }
   ],
   "source": [
    "n = 7192\n",
    "\n",
    "x = int(n / 10) +1\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /disk/project/corpus/test_1.conll\n",
      "saved srls: 42665\n",
      "saved to: /disk/project/corpus/test_2.conll\n",
      "saved srls: 43655\n",
      "saved to: /disk/project/corpus/test_3.conll\n",
      "saved srls: 43439\n",
      "saved to: /disk/project/corpus/test_4.conll\n",
      "saved srls: 43094\n",
      "saved to: /disk/project/corpus/test_5.conll\n",
      "saved srls: 42562\n",
      "saved to: /disk/project/corpus/test_6.conll\n",
      "saved srls: 45155\n",
      "saved to: /disk/project/corpus/test_7.conll\n",
      "saved srls: 43780\n",
      "saved to: /disk/project/corpus/test_8.conll\n",
      "saved srls: 43507\n",
      "saved to: /disk/project/corpus/test_9.conll\n",
      "saved srls: 42879\n",
      "saved to: /disk/project/corpus/test_10.conll\n",
      "saved srls: 42043\n"
     ]
    }
   ],
   "source": [
    "# test data\n",
    "const_dir = '/disk/project/corpus/dataArchive/7_srl/const/converted/written_0217/'\n",
    "const_files = glob.glob(const_dir+'*')\n",
    "\n",
    "def chunks(l, n):\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i+n]\n",
    "        \n",
    "devided_const_files = list(chunks(const_files, int(len(const_files)/10)+1))\n",
    "\n",
    "\n",
    "n = 1\n",
    "for files in devided_const_files:\n",
    "    save_fname = '/disk/project/corpus/test_'+str(n)+'.conll'\n",
    "    converter(files, save_fname)\n",
    "    n +=1\n",
    "    \n",
    "ns = [1,2,3,4,5,6,7,8,9,10]\n",
    "with open('./srl_splits.txt','w') as f1:\n",
    "    for n in ns:\n",
    "        fname = '/disk/project/corpus/test_'+str(n)+'.conll'\n",
    "        with open(fname, 'r') as f2:\n",
    "            x = f2.readlines()\n",
    "            \n",
    "        docid = x[0]\n",
    "        line = '\\t' + docid + '\\n'\n",
    "        f1.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/tag2idx.json') as f:\n",
    "    tag2idx = json.load(f)\n",
    "\n",
    "def error_checker(files):\n",
    "    conll = []\n",
    "    \n",
    "    doc_list = []\n",
    "    for fname in files:        \n",
    "        docid = fname.split('/')[-1].split('.')[0]\n",
    "        \n",
    "        with open(fname, 'r') as f:\n",
    "            d = json.load(f)\n",
    "            \n",
    "        for doc in d['document']:\n",
    "            for sent in doc['sentence']:\n",
    "                sent_id = sent['id']\n",
    "                words = sent['word']\n",
    "                srl = sent['SRL']\n",
    "                srl_conll = convert_for_sent(srl, words)\n",
    "                \n",
    "                for i in srl_conll:\n",
    "                    args = i[-1]\n",
    "                    \n",
    "                    for a in args:\n",
    "                        if a not in tag2idx:\n",
    "                            print(sent_id, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NWRW1800000038-0234.32 >>>\n",
      "NWRW1800000030-0145.4 ARGM_LOC(장소)\n",
      "NWRW1800000041-0097.5 ARR2\n"
     ]
    }
   ],
   "source": [
    "# error checker\n",
    "const_dir = '/disk/project/corpus/dataArchive/7_srl/const/converted/written_0217/'\n",
    "const_files = glob.glob(const_dir+'*')\n",
    "\n",
    "error_checker(const_files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
